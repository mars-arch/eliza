export const modelConfig = {
    type: 'local',
    modelName: 'llama2',
    modelPath: '../Llama-3.2-3B-Instruct', // Relative path to your model
    endpoint: 'http://localhost:11434' // If using Ollama, or adjust for your setup
  }